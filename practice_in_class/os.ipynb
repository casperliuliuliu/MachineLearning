{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liushiwen/Desktop/大四上/機器學習導論 ['compete', 'MachineLearning', 'hw1', 'd2l-zh'] ['20211108 ensemble.pdf', '.DS_Store', '20211101 classfication.pdf', '20201026 decisiontree.pdf', '20201109 Neural Network.pdf', '20211213 tensorflow.pdf', '20201019 SVM.pdf', '20211115 Unsupervised Learning.pdf', '20211025 regression.pdf', 'Syllabus2023.pdf', '20230904 course_intro.pdf', '20200907 Python_Programming.pdf']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/compete ['code', 'data'] ['.DS_Store']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/compete/code [] ['read.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/compete/data ['30_Training Dataset_V2', '30_Public Dataset_Public Sumission Template_v2'] ['.DS_Store', 'Sinopac Slack Link.txt']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/compete/data/30_Training Dataset_V2 ['external_data'] ['.DS_Store', 'training_data.csv']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/compete/data/30_Training Dataset_V2/external_data [] ['高中基本資料.csv', '國小基本資料.csv', '火車站點資料.csv', '腳踏車站點資料.csv', '醫療機構基本資料.csv', '公車站點資料.csv', '國中基本資料.csv', '大學基本資料.csv', '便利商店.csv', 'ATM資料.csv', '金融機構基本資料.csv', '捷運站點資料.csv', '郵局據點資料.csv']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/compete/data/30_Public Dataset_Public Sumission Template_v2 [] ['public_submission_template.csv', 'public_dataset.csv']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning ['practice_in_class', 'hw1', '.git'] ['.DS_Store', 'README.md']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/practice_in_class [] ['matplotlib.ipynb', 'os.ipynb', 'numpy.ipynb', 'class_call.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw1 ['test', '.ipynb_checkpoints', 'reference'] ['HW1_data.csv', 'hw1_2.ipynb', 'hw1_1.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw1/test [] ['pic13.jpg', 'pic9.jpg', 'pic8.jpg', 'pic12.jpg', 'pic10.jpg', 'pic11.jpg', 'pic15.jpg', 'pic14.jpg', 'pic16.jpg', 'pic17.jpg', 'pic1.jpg', 'pic19.jpg', 'pic3.jpg', 'pic2.jpg', 'pic18.jpg', 'pic20.jpg', 'pic6.jpg', 'pic7.jpg', 'pic5.jpg', 'pic4.jpg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw1/.ipynb_checkpoints [] ['hw1_2-checkpoint.ipynb', 'hw1_1-checkpoint.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw1/reference ['dogs', 'cats'] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw1/reference/dogs [] ['dog.36.jpg', 'dog.22.jpg', 'dog.23.jpg', 'dog.37.jpg', 'dog.21.jpg', 'dog.35.jpg', 'dog.34.jpg', 'dog.20.jpg', 'dog.24.jpg', 'dog.30.jpg', 'dog.18.jpg', 'dog.19.jpg', 'dog.31.jpg', 'dog.25.jpg', 'dog.33.jpg', 'dog.27.jpg', 'dog.26.jpg', 'dog.32.jpg', 'dog.1.jpg', 'dog.41.jpg', 'dog.40.jpg', 'dog.2.jpg', 'dog.42.jpg', 'dog.43.jpg', 'dog.3.jpg', 'dog.47.jpg', 'dog.7.jpg', 'dog.6.jpg', 'dog.46.jpg', 'dog.50.jpg', 'dog.44.jpg', 'dog.4.jpg', 'dog.5.jpg', 'dog.45.jpg', 'dog.8.jpg', 'dog.48.jpg', 'dog.49.jpg', 'dog.9.jpg', 'dog.17.jpg', 'dog.16.jpg', 'dog.28.jpg', 'dog.14.jpg', 'dog.15.jpg', 'dog.29.jpg', 'dog.11.jpg', 'dog.39.jpg', 'dog.38.jpg', 'dog.10.jpg', 'dog.12.jpg', 'dog.13.jpg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw1/reference/cats [] ['cat.6.jpg', 'cat.30.jpg', 'cat.24.jpg', 'cat.18.jpg', 'cat.19.jpg', 'cat.25.jpg', 'cat.31.jpg', 'cat.7.jpg', 'cat.5.jpg', 'cat.27.jpg', 'cat.33.jpg', 'cat.32.jpg', 'cat.26.jpg', 'cat.4.jpg', 'cat.22.jpg', 'cat.36.jpg', 'cat.37.jpg', 'cat.23.jpg', 'cat.1.jpg', 'cat.3.jpg', 'cat.35.jpg', 'cat.21.jpg', 'cat.20.jpg', 'cat.34.jpg', 'cat.2.jpg', 'cat.47.jpg', 'cat.46.jpg', 'cat.44.jpg', 'cat.50.jpg', 'cat.45.jpg', 'cat.41.jpg', 'cat.40.jpg', 'cat.42.jpg', 'cat.43.jpg', 'cat.48.jpg', 'cat.49.jpg', 'cat.11.jpg', 'cat.39.jpg', 'cat.38.jpg', 'cat.10.jpg', 'cat.12.jpg', 'cat.13.jpg', 'cat.9.jpg', 'cat.17.jpg', 'cat.16.jpg', 'cat.8.jpg', 'cat.28.jpg', 'cat.14.jpg', 'cat.15.jpg', 'cat.29.jpg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git ['objects', 'info', 'logs', 'hooks', 'refs'] ['ORIG_HEAD', 'config', 'HEAD', 'description', 'index', 'packed-refs', 'COMMIT_EDITMSG', 'FETCH_HEAD']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects ['0d', '3b', '6f', '60', '02', 'd0', 'bd', 'd6', 'd8', 'fe', 'c1', 'pack', '1f', '87', '28', '8a', '88', '6b', '00', '5c', '5d', 'info', '08', '6d', '39', '55', 'dd', 'b6', 'a1', 'c4', 'e6', 'f9', 'f0', 'ff', 'c2', 'f1', '83', '48', '84', '4f', '15', '8b', '7f', '22'] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/0d [] ['a778581686e2adc1b89b6960d3aade7a903400']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/3b [] ['5ca345f8d2ff7b4eadcb42a0987626e5f7bad8']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/6f [] ['abfbc6fabd790e0d8597bd7cc5e6e3f75ec425', '7a14350a6c2233d175f3fd992667f658b17ca8']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/60 [] ['e6c2ac01ae2c9ff7bbae48df2714ac04f20c76']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/02 [] ['bf381fc48cc7798c621bf3af0749ca0d463698']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/d0 [] ['9eaaa257412184b56d0acdf42c12078be277d4']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/bd [] ['dc95946cb082cb7c837ce89a244256265d856e']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/d6 [] ['c1338f6ea1797d0d9ece26eee3475c21350a9e']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/d8 [] ['0a5195726c208fd2585a733f4714104ed5b592']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/fe [] ['cf1bb0f46e62b0550f7e6c1e1a45bddf6363fe']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/c1 [] ['b96064afbc8006f5ad08f2b0543404a12da071']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/pack [] ['pack-149e6a0f6e2125f1805749638ed32b7823262a8f.idx', 'pack-149e6a0f6e2125f1805749638ed32b7823262a8f.pack', 'pack-149e6a0f6e2125f1805749638ed32b7823262a8f.rev']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/1f [] ['fdd385413fbbbb29b49e86826634e1be9f2d6d']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/87 [] ['92f8848345d1fc80c0f25f2793e32e94efbdc4']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/28 [] ['c312258a9c1bf6ec13f71b244cdbdac7ff0676']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/8a [] ['314ae30819b70faf696bedf75cb6aa67079352']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/88 [] ['9a7898ee3867b37fe34a12b1fa1b3f54cb2259']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/6b [] ['9b819335c5c55c6f5976626750ff637ae41d70']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/00 [] ['63df63bbf6bf93b8e5226b419cdbc5d8ed5f6b']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/5c [] ['bac0ba312405ee12bc14ae2397146253db8de7']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/5d [] ['74a03500772d635745266ba77b9f2910da4302']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/info [] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/08 [] ['6efb58afc8a75f36902b707e4763462d4e7eb9']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/6d [] ['1677da6d093299593024b25ba23c72bb3d38b9']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/39 [] ['8ead46f37b0f900501b45b9b15f246b375c937']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/55 [] ['95bebdd83005ba78f3c821bb8082c38455793c']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/dd [] ['8e689b579eec8c1b01f5a3a354e1c8e31ffc32']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/b6 [] ['6f3a0ac31f51a90b9558ff51510abe7ac7fa83']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/a1 [] ['55bf0c80f79753d59dfe824248f89dbea262e6']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/c4 [] ['fc7bd3aeb1c2b8374f1812c80a0e7666edeb71']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/e6 [] ['d49dad4a29491495901c9634113aa127dc5ea9']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/f9 [] ['5888e315d12165640f4354cc8b2539dc92f4d7']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/f0 [] ['1a9a14c25d716445f876aa494e506d9b6b309d']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/ff [] ['2bcf290c1491fc7c3cf88f597111fef61ac6d0']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/c2 [] ['ac29da3fdf76026358841b0504edf08ec481f7']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/f1 [] ['5164378982b01c8130f78d76a02740130af7f1']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/83 [] ['9c9e5b944032f8f3baecb00efb943e586a59a5']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/48 [] ['0b7ca52adc690e0e6ab826c6d1dbcd1cdbbcc8']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/84 [] ['1f7cbee86924ddb2e8eeac77421f8860c2d679']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/4f [] ['ba5ad6cd8b5c38443b18a084ebb3e16b394a8f']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/15 [] ['443f1979fea0a17b84394bcfe1eebfd28cb1ea']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/8b [] ['56492675e4436c8797559a3926168ddb8e36c4']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/7f [] ['73410530a0bd9e996a689a86725da0c5e52a12']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/objects/22 [] ['6cf90c21cd6fe046de1c24fa0c6e887cab0d11']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/info [] ['exclude']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/logs ['refs'] ['HEAD']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/logs/refs ['heads', 'remotes'] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/logs/refs/heads [] ['main']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/logs/refs/remotes ['origin'] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/logs/refs/remotes/origin [] ['HEAD', 'main']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/hooks [] ['commit-msg.sample', 'pre-rebase.sample', 'sendemail-validate.sample', 'pre-commit.sample', 'applypatch-msg.sample', 'fsmonitor-watchman.sample', 'pre-receive.sample', 'prepare-commit-msg.sample', 'post-update.sample', 'pre-merge-commit.sample', 'pre-applypatch.sample', 'pre-push.sample', 'update.sample', 'push-to-checkout.sample']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/refs ['heads', 'tags', 'remotes'] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/refs/heads [] ['main']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/refs/tags [] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/refs/remotes ['origin'] []\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/.git/refs/remotes/origin [] ['HEAD', 'main']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1 ['HW1 附件'] ['.DS_Store', 'Y2023 HW1.pdf']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1/HW1 附件 ['HW1 image'] ['HW1 image.zip', '.DS_Store', 'HW1_data.csv']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1/HW1 附件/HW1 image ['test', 'reference'] ['.DS_Store']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1/HW1 附件/HW1 image/test [] ['pic13.jpg', 'pic9.jpg', 'pic8.jpg', 'pic12.jpg', 'pic10.jpg', 'pic11.jpg', 'pic15.jpg', 'pic14.jpg', 'pic16.jpg', 'pic17.jpg', 'pic1.jpg', 'pic19.jpg', 'pic3.jpg', 'pic2.jpg', 'pic18.jpg', 'pic20.jpg', 'pic6.jpg', 'pic7.jpg', 'pic5.jpg', 'pic4.jpg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1/HW1 附件/HW1 image/reference ['dogs', 'cats'] ['.DS_Store']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1/HW1 附件/HW1 image/reference/dogs [] ['dog.36.jpg', 'dog.22.jpg', 'dog.23.jpg', 'dog.37.jpg', 'dog.21.jpg', 'dog.35.jpg', 'dog.34.jpg', 'dog.20.jpg', 'dog.24.jpg', 'dog.30.jpg', 'dog.18.jpg', 'dog.19.jpg', 'dog.31.jpg', 'dog.25.jpg', 'dog.33.jpg', 'dog.27.jpg', 'dog.26.jpg', 'dog.32.jpg', 'dog.1.jpg', 'dog.41.jpg', 'dog.40.jpg', 'dog.2.jpg', 'dog.42.jpg', 'dog.43.jpg', 'dog.3.jpg', 'dog.47.jpg', 'dog.7.jpg', 'dog.6.jpg', 'dog.46.jpg', 'dog.50.jpg', 'dog.44.jpg', 'dog.4.jpg', 'dog.5.jpg', 'dog.45.jpg', 'dog.8.jpg', 'dog.48.jpg', 'dog.49.jpg', 'dog.9.jpg', 'dog.17.jpg', 'dog.16.jpg', 'dog.28.jpg', 'dog.14.jpg', 'dog.15.jpg', 'dog.29.jpg', 'dog.11.jpg', 'dog.39.jpg', 'dog.38.jpg', 'dog.10.jpg', 'dog.12.jpg', 'dog.13.jpg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/hw1/HW1 附件/HW1 image/reference/cats [] ['cat.6.jpg', 'cat.30.jpg', 'cat.24.jpg', 'cat.18.jpg', 'cat.19.jpg', 'cat.25.jpg', 'cat.31.jpg', 'cat.7.jpg', 'cat.5.jpg', 'cat.27.jpg', 'cat.33.jpg', 'cat.32.jpg', 'cat.26.jpg', 'cat.4.jpg', 'cat.22.jpg', 'cat.36.jpg', 'cat.37.jpg', 'cat.23.jpg', 'cat.1.jpg', 'cat.3.jpg', 'cat.35.jpg', 'cat.21.jpg', 'cat.20.jpg', 'cat.34.jpg', 'cat.2.jpg', 'cat.47.jpg', 'cat.46.jpg', 'cat.44.jpg', 'cat.50.jpg', 'cat.45.jpg', 'cat.41.jpg', 'cat.40.jpg', 'cat.42.jpg', 'cat.43.jpg', 'cat.48.jpg', 'cat.49.jpg', 'cat.11.jpg', 'cat.39.jpg', 'cat.38.jpg', 'cat.10.jpg', 'cat.12.jpg', 'cat.13.jpg', 'cat.9.jpg', 'cat.17.jpg', 'cat.16.jpg', 'cat.8.jpg', 'cat.28.jpg', 'cat.14.jpg', 'cat.15.jpg', 'cat.29.jpg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh ['mxnet', 'paddle', 'tensorflow', 'pytorch'] ['.DS_Store']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet ['chapter_appendix-tools-for-deep-learning', 'chapter_references', 'chapter_linear-networks', 'chapter_multilayer-perceptrons', 'chapter_convolutional-modern', 'chapter_preliminaries', 'chapter_computer-vision', 'chapter_recurrent-neural-networks', 'img', 'chapter_natural-language-processing-pretraining', 'chapter_notation', 'chapter_convolutional-neural-networks', 'chapter_preface', 'chapter_installation', 'chapter_computational-performance', 'chapter_deep-learning-computation', 'chapter_recurrent-modern', 'chapter_attention-mechanisms', 'chapter_natural-language-processing-applications', 'chapter_optimization', 'chapter_introduction'] ['d2l.bib', 'setup.py', 'TERMINOLOGY.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_appendix-tools-for-deep-learning [] ['contributing.ipynb', 'jupyter.ipynb', 'selecting-servers-gpus.ipynb', 'aws.ipynb', 'sagemaker.ipynb', 'd2l.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_references [] ['zreferences.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_linear-networks [] ['linear-regression-scratch.ipynb', 'linear-regression-concise.ipynb', 'softmax-regression.ipynb', 'softmax-regression-concise.ipynb', 'softmax-regression-scratch.ipynb', 'linear-regression.ipynb', 'image-classification-dataset.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_multilayer-perceptrons [] ['dropout.ipynb', 'submission.csv', 'mlp.ipynb', 'weight-decay.ipynb', 'mlp-concise.ipynb', 'mlp-scratch.ipynb', 'underfit-overfit.ipynb', 'kaggle-house-price.ipynb', 'backprop.ipynb', 'numerical-stability-and-init.ipynb', 'environment.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_convolutional-modern [] ['vgg.ipynb', 'densenet.ipynb', 'googlenet.ipynb', 'nin.ipynb', 'batch-norm.ipynb', 'alexnet.ipynb', 'resnet.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_preliminaries [] ['calculus.ipynb', 'ndarray.ipynb', 'linear-algebra.ipynb', 'probability.ipynb', 'pandas.ipynb', 'index.ipynb', 'lookup-api.ipynb', 'autograd.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_computer-vision [] ['fcn.ipynb', 'submission.csv', 'image-augmentation.ipynb', 'transposed-conv.ipynb', 'rcnn.ipynb', 'kaggle-dog.ipynb', 'ssd.ipynb', 'neural-style.ipynb', 'multiscale-object-detection.ipynb', 'fine-tuning.ipynb', 'object-detection-dataset.ipynb', 'bounding-box.ipynb', 'anchor.ipynb', 'index.ipynb', 'kaggle-cifar10.ipynb', 'semantic-segmentation-and-dataset.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_recurrent-neural-networks [] ['language-models-and-dataset.ipynb', 'text-preprocessing.ipynb', 'rnn.ipynb', 'sequence.ipynb', 'rnn-concise.ipynb', 'rnn-scratch.ipynb', 'bptt.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/img ['frontends'] ['rainier.jpg', 'chain-net1.svg', 'falsesharing.svg', 'bert-one-seq.svg', 'seq2seq-details.svg', 'data-collection.svg', 'neon128.svg', 'statistical-significance.svg', 'rec-mf.svg', 'conv-multi-in.svg', 'cat-dog-train.svg', 'git-newpr.png', 'mask-rcnn.svg', 'negSecDer.svg', 'softmaxreg.svg', 'eye-coffee.svg', 'ml-loop.svg', 'textcnn.svg', 'death-cap.jpg', 'neural-style.svg', 's2s-prob2.svg', 'chain-net2.svg', 'supervised-learning.svg', 'git-clone.png', 'data-parallel.svg', 'git-fork.png', 'filters.png', 'tensorcore.jpg', 'transformer.svg', 'sagemaker.png', 'mlp.svg', 's2s-prob1.svg', 'bert-input.svg', 'skip-gram.svg', 'qkv.svg', 'copyto.svg', 'seq2seq-attention.svg', 'inception-full.svg', 'lstm-0.svg', 'rec-intro.svg', 'trans_conv_stride2.svg', 'frontends.svg', 'waldo-mask.jpg', 'house-pricing.png', 'seq2seq-predict.svg', 'conv1d-2d.svg', 'gan.svg', 'rl-environment.svg', 'dog2.jpg', 'conv-1x1.svg', 'p2x.png', 'rnn.svg', 'lstm-1.svg', 'proj-vec.svg', 'ssd.svg', 'flopsvsprice.svg', 'lstm-3.svg', 'rec-deepfm.svg', 'projections.svg', 'nvlink-twoloop.svg', 'nin.svg', 'asyncgraph.svg', 'dog1.jpg', 'pikachu.jpg', 'roi.svg', 'lstm-2.svg', 'birnn.svg', 'chmod.png', 'r-cnn.svg', 'lenet.svg', 'resnet-block.svg', 'cnn-rnn-self-attention.svg', 'cat1.jpg', 'bert-tagging.svg', 'cuda101.png', 'jupyter06.png', 'kaggle.png', 'densenet.svg', 'trans_conv.svg', 'style-transfer.svg', 'popvssoda.png', 'faster-rcnn.svg', 'conv-pad.svg', 'capacity_vs_error.svg', 'sequence-model.svg', 'attention.svg', 'seq2seq-attention-details.svg', 'computegraph.svg', 'cat2.jpg', 'cat-dog-pixels.png', 'colab.png', 'jupyter05.png', 'ec2.png', 'conv1d-channel.svg', 'alexnet-original.svg', 'frontends.png', 'jupyter04.png', 'sagemaker-create.png', 'cat3.jpg', 'vec-add.svg', 'seq2seq.svg', 'jupyter.png', 'deeplearning-amazon.jpg', 'aws.png', 'vgg.svg', 'launching.png', 'sagemaker-create-3-pytorch.png', 'sagemaker-open.png', 'nlp-map-sa-rnn.svg', 'ps-distributed.svg', 'jupyter00.png', 'jupyter01.png', 'nlp-map-nli-attention.svg', 'conv1d.svg', 'fit-linreg.svg', 'timemachine-5gram.svg', 'wattvsprice.svg', 'neural-style.jpg', 'attention-output.svg', 'where-wally-walker-books.jpg', 'turing-processing-block.png', 'contribute.svg', 'eye-coffee.png', 'anchor-label.svg', 'densenet-block.svg', 'kaggle-cifar10.png', 'jupyter03.png', 'jupyter02.png', 'splitting.svg', 'grid-points.svg', 'threading.svg', 'blocks.svg', 'connect.png', 'dropout2.svg', 'hi-softmax.svg', 'wake-word.svg', 'mutual-information.svg', 'nvlink.svg', 'rnn-train.svg', 'singleneuron.svg', 'catdog.jpg', 'lang-model-data.svg', 'lenet-vert.svg', 'conv-stride.svg', 'nlp-map-pretrain.svg', 'par-vec.svg', 'mobo-symbol.svg', 'resnet18.svg', 'add_norm.svg', 'residual-block.svg', 'zeroSecDer.svg', 'edit-file.png', 'cbow.svg', 'posSecDer.svg', 'sagemaker-create-3.png', 'inception.svg', 'git-createpr.png', 'pacman.svg', 'truncated-bptt.svg', 'limits.png', 'sagemaker-create-2.png', 'hmm.svg', 'sagemaker-terminal.png', 'eye-book.png', 'rec-neumf.svg', 'ftse100.png', 'rect-trans.svg', 'nlp-map-nli-bert.svg', 'finetune.svg', 'twogpu.svg', 'rec-caser.svg', 'capacity-vs-error.svg', 'alexnet.svg', 'Marginal.svg', 'convex-intersect.svg', 'ubuntu-new.png', 'Neuron.svg', 'kaggle-submit2.png', 'fcn.svg', 'ringsync.svg', 'ps-multips.svg', 'nlp-map-sa-cnn.svg', 'rec-seq-data.svg', 'rec-ranking.svg', 'functionclasses.svg', 'sagemaker-stop.png', 'nonconvex.svg', 'book-org.svg', 'elmo-gpt-bert.svg', 'ps-multimachine.svg', 'a77.svg', 'singlelayer.svg', 'pooling.svg', 'banana.jpg', 'falseshare.svg', 'bert-two-seqs.svg', 'self-attention.svg', 'encoder-decoder.svg', 'nlp-map-app.svg', 'grid-transform.svg', 'multi-head-attention.svg', 'deep-rnn.svg', 'grid-transform-filled.svg', 'eye-book.svg', 'sub-area.svg', 'nin-compare.svg', 'polygon-circle.svg', 'disk.png', 'space-division-3d.svg', 'nli-attention.svg', 'sum-order.svg', 'beam-search.svg', 'correlation.svg', 'nli_attention.svg', 'colab-2.png', 'forward.svg', 'latencynumbers.png', 'rnn-bptt.svg', 'gru-2.svg', 'iou.svg', 'turing.png', 'speech.png', 'koebel.jpg', 'gru-3.svg', 'fast-rcnn.svg', 'git-forked.png', 'sagemaker-create-3-tensorflow.png', 'space-division.svg', 'cat-dog-test.svg', 'vec-angle.svg', 'stackedanimals.png', 'ps.svg', 'segmentation.svg', 'kaggle-dog.jpg', 'keypair.png', 'gru-1.svg', 'autumn-oak.jpg', 'bw-hierarchy.svg', 'skylake.svg', 'bert-qa.svg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/img/frontends [] ['Canvas 1.svg', 'image10.tiff', 'image8.tiff', 'image4.tiff', 'image5.pdf', 'image3.tiff', 'image2.tiff']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_natural-language-processing-pretraining [] ['glove.ipynb', 'word-embedding-dataset.ipynb', 'bert-dataset.ipynb', 'subword-embedding.ipynb', 'word2vec.ipynb', 'similarity-analogy.ipynb', 'word2vec-pretraining.ipynb', 'bert-pretraining.ipynb', 'approx-training.ipynb', 'bert.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_notation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_convolutional-neural-networks [] ['why-conv.ipynb', 'pooling.ipynb', 'conv-layer.ipynb', 'lenet.ipynb', 'index.ipynb', 'channels.ipynb', 'padding-and-strides.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_preface [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_installation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_computational-performance [] ['parameterserver.ipynb', 'my_mlp-symbol.json', 'multiple-gpus-concise.ipynb', 'hybridize.ipynb', 'my_mlp-0000.params', 'async-computation.ipynb', 'hardware.ipynb', 'auto-parallelism.ipynb', 'index.ipynb', 'multiple-gpus.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_deep-learning-computation [] ['use-gpu.ipynb', 'model-construction.ipynb', 'x-files', 'custom-layer.ipynb', 'mydict', 'mlp.params', 'x-file', 'deferred-init.ipynb', 'parameters.ipynb', 'index.ipynb', 'read-write.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_recurrent-modern [] ['deep-rnn.ipynb', 'lstm.ipynb', 'seq2seq.ipynb', 'bi-rnn.ipynb', 'machine-translation-and-dataset.ipynb', 'gru.ipynb', 'encoder-decoder.ipynb', 'index.ipynb', 'beam-search.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_attention-mechanisms [] ['nadaraya-waston.ipynb', 'attention-cues.ipynb', 'self-attention-and-positional-encoding.ipynb', 'bahdanau-attention.ipynb', 'multihead-attention.ipynb', 'transformer.ipynb', 'index.ipynb', 'attention-scoring-functions.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_natural-language-processing-applications [] ['natural-language-inference-bert.ipynb', 'natural-language-inference-attention.ipynb', 'sentiment-analysis-cnn.ipynb', 'finetuning-bert.ipynb', 'natural-language-inference-and-dataset.ipynb', 'sentiment-analysis-and-dataset.ipynb', 'index.ipynb', 'sentiment-analysis-rnn.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_optimization [] ['momentum.ipynb', 'rmsprop.ipynb', 'convexity.ipynb', 'optimization-intro.ipynb', 'lr-scheduler.ipynb', 'sgd.ipynb', 'adam.ipynb', 'minibatch-sgd.ipynb', 'adadelta.ipynb', 'gd.ipynb', 'index.ipynb', 'adagrad.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/mxnet/chapter_introduction [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle ['chapter_appendix-tools-for-deep-learning', 'chapter_references', 'chapter_linear-networks', 'chapter_multilayer-perceptrons', 'chapter_convolutional-modern', 'chapter_preliminaries', 'chapter_computer-vision', 'chapter_recurrent-neural-networks', 'img', 'chapter_natural-language-processing-pretraining', 'chapter_notation', 'chapter_convolutional-neural-networks', 'chapter_preface', 'chapter_installation', 'chapter_computational-performance', 'chapter_deep-learning-computation', 'chapter_recurrent-modern', 'chapter_attention-mechanisms', 'chapter_natural-language-processing-applications', 'chapter_optimization', 'chapter_introduction'] ['d2l.bib', 'setup.py', 'TERMINOLOGY.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_appendix-tools-for-deep-learning [] ['contributing.ipynb', 'jupyter.ipynb', 'selecting-servers-gpus.ipynb', 'aws.ipynb', 'sagemaker.ipynb', 'd2l.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_references [] ['zreferences.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_linear-networks [] ['linear-regression-scratch.ipynb', 'linear-regression-concise.ipynb', 'softmax-regression.ipynb', 'softmax-regression-concise.ipynb', 'softmax-regression-scratch.ipynb', 'linear-regression.ipynb', 'image-classification-dataset.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_multilayer-perceptrons [] ['dropout.ipynb', 'submission.csv', 'mlp.ipynb', 'weight-decay.ipynb', 'mlp-concise.ipynb', 'mlp-scratch.ipynb', 'underfit-overfit.ipynb', 'kaggle-house-price.ipynb', 'backprop.ipynb', 'numerical-stability-and-init.ipynb', 'environment.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_convolutional-modern [] ['vgg.ipynb', 'densenet.ipynb', 'googlenet.ipynb', 'nin.ipynb', 'batch-norm.ipynb', 'alexnet.ipynb', 'resnet.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_preliminaries [] ['calculus.ipynb', 'ndarray.ipynb', 'linear-algebra.ipynb', 'probability.ipynb', 'pandas.ipynb', 'index.ipynb', 'lookup-api.ipynb', 'autograd.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_computer-vision [] ['fcn.ipynb', 'submission.csv', 'image-augmentation.ipynb', 'transposed-conv.ipynb', 'rcnn.ipynb', 'kaggle-dog.ipynb', 'ssd.ipynb', 'neural-style.ipynb', 'multiscale-object-detection.ipynb', 'fine-tuning.ipynb', 'object-detection-dataset.ipynb', 'bounding-box.ipynb', 'anchor.ipynb', 'index.ipynb', 'kaggle-cifar10.ipynb', 'semantic-segmentation-and-dataset.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_recurrent-neural-networks [] ['language-models-and-dataset.ipynb', 'text-preprocessing.ipynb', 'rnn.ipynb', 'sequence.ipynb', 'rnn-concise.ipynb', 'rnn-scratch.ipynb', 'bptt.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/img ['frontends'] ['rainier.jpg', 'chain-net1.svg', 'falsesharing.svg', 'bert-one-seq.svg', 'seq2seq-details.svg', 'data-collection.svg', 'neon128.svg', 'statistical-significance.svg', 'rec-mf.svg', 'conv-multi-in.svg', 'cat-dog-train.svg', 'git-newpr.png', 'mask-rcnn.svg', 'negSecDer.svg', 'softmaxreg.svg', 'eye-coffee.svg', 'ml-loop.svg', 'textcnn.svg', 'death-cap.jpg', 'neural-style.svg', 's2s-prob2.svg', 'chain-net2.svg', 'supervised-learning.svg', 'git-clone.png', 'data-parallel.svg', 'git-fork.png', 'filters.png', 'tensorcore.jpg', 'transformer.svg', 'sagemaker.png', 'mlp.svg', 's2s-prob1.svg', 'bert-input.svg', 'skip-gram.svg', 'qkv.svg', 'copyto.svg', 'seq2seq-attention.svg', 'inception-full.svg', 'lstm-0.svg', 'rec-intro.svg', 'trans_conv_stride2.svg', 'frontends.svg', 'waldo-mask.jpg', 'house-pricing.png', 'seq2seq-predict.svg', 'conv1d-2d.svg', 'gan.svg', 'rl-environment.svg', 'dog2.jpg', 'conv-1x1.svg', 'p2x.png', 'rnn.svg', 'lstm-1.svg', 'proj-vec.svg', 'ssd.svg', 'flopsvsprice.svg', 'lstm-3.svg', 'rec-deepfm.svg', 'projections.svg', 'nvlink-twoloop.svg', 'nin.svg', 'asyncgraph.svg', 'dog1.jpg', 'pikachu.jpg', 'roi.svg', 'lstm-2.svg', 'birnn.svg', 'chmod.png', 'r-cnn.svg', 'lenet.svg', 'resnet-block.svg', 'cnn-rnn-self-attention.svg', 'cat1.jpg', 'bert-tagging.svg', 'cuda101.png', 'jupyter06.png', 'kaggle.png', 'densenet.svg', 'trans_conv.svg', 'style-transfer.svg', 'popvssoda.png', 'faster-rcnn.svg', 'conv-pad.svg', 'capacity_vs_error.svg', 'sequence-model.svg', 'attention.svg', 'seq2seq-attention-details.svg', 'computegraph.svg', 'cat2.jpg', 'cat-dog-pixels.png', 'colab.png', 'jupyter05.png', 'ec2.png', 'conv1d-channel.svg', 'alexnet-original.svg', 'frontends.png', 'jupyter04.png', 'sagemaker-create.png', 'cat3.jpg', 'vec-add.svg', 'seq2seq.svg', 'jupyter.png', 'deeplearning-amazon.jpg', 'aws.png', 'vgg.svg', 'launching.png', 'sagemaker-create-3-pytorch.png', 'sagemaker-open.png', 'nlp-map-sa-rnn.svg', 'ps-distributed.svg', 'jupyter00.png', 'jupyter01.png', 'nlp-map-nli-attention.svg', 'conv1d.svg', 'fit-linreg.svg', 'timemachine-5gram.svg', 'wattvsprice.svg', 'neural-style.jpg', 'attention-output.svg', 'where-wally-walker-books.jpg', 'turing-processing-block.png', 'contribute.svg', 'eye-coffee.png', 'anchor-label.svg', 'densenet-block.svg', 'kaggle-cifar10.png', 'jupyter03.png', 'jupyter02.png', 'splitting.svg', 'grid-points.svg', 'threading.svg', 'blocks.svg', 'connect.png', 'dropout2.svg', 'hi-softmax.svg', 'wake-word.svg', 'mutual-information.svg', 'nvlink.svg', 'rnn-train.svg', 'singleneuron.svg', 'catdog.jpg', 'lang-model-data.svg', 'lenet-vert.svg', 'conv-stride.svg', 'nlp-map-pretrain.svg', 'par-vec.svg', 'mobo-symbol.svg', 'resnet18.svg', 'add_norm.svg', 'residual-block.svg', 'zeroSecDer.svg', 'edit-file.png', 'cbow.svg', 'posSecDer.svg', 'sagemaker-create-3.png', 'inception.svg', 'git-createpr.png', 'pacman.svg', 'truncated-bptt.svg', 'limits.png', 'sagemaker-create-2.png', 'hmm.svg', 'sagemaker-terminal.png', 'eye-book.png', 'rec-neumf.svg', 'ftse100.png', 'rect-trans.svg', 'nlp-map-nli-bert.svg', 'finetune.svg', 'twogpu.svg', 'rec-caser.svg', 'capacity-vs-error.svg', 'alexnet.svg', 'marginal.svg', 'convex-intersect.svg', 'ubuntu-new.png', 'neuron.svg', 'kaggle-submit2.png', 'fcn.svg', 'ringsync.svg', 'ps-multips.svg', 'nlp-map-sa-cnn.svg', 'rec-seq-data.svg', 'rec-ranking.svg', 'functionclasses.svg', 'sagemaker-stop.png', 'nonconvex.svg', 'book-org.svg', 'elmo-gpt-bert.svg', 'ps-multimachine.svg', 'a77.svg', 'singlelayer.svg', 'pooling.svg', 'banana.jpg', 'falseshare.svg', 'bert-two-seqs.svg', 'self-attention.svg', 'encoder-decoder.svg', 'nlp-map-app.svg', 'grid-transform.svg', 'multi-head-attention.svg', 'deep-rnn.svg', 'grid-transform-filled.svg', 'eye-book.svg', 'sub-area.svg', 'nin-compare.svg', 'polygon-circle.svg', 'disk.png', 'space-division-3d.svg', 'nli-attention.svg', 'sum-order.svg', 'beam-search.svg', 'correlation.svg', 'nli_attention.svg', 'colab-2.png', 'forward.svg', 'latencynumbers.png', 'rnn-bptt.svg', 'gru-2.svg', 'iou.svg', 'turing.png', 'speech.png', 'koebel.jpg', 'gru-3.svg', 'fast-rcnn.svg', 'git-forked.png', 'sagemaker-create-3-tensorflow.png', 'space-division.svg', 'cat-dog-test.svg', 'vec-angle.svg', 'stackedanimals.png', 'ps.svg', 'segmentation.svg', 'kaggle-dog.jpg', 'keypair.png', 'gru-1.svg', 'autumn-oak.jpg', 'bw-hierarchy.svg', 'skylake.svg', 'bert-qa.svg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/img/frontends [] ['Canvas 1.svg', 'image10.tiff', 'image8.tiff', 'image4.tiff', 'image5.pdf', 'image3.tiff', 'image2.tiff']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_natural-language-processing-pretraining [] ['glove.ipynb', 'word-embedding-dataset.ipynb', 'bert-dataset.ipynb', 'subword-embedding.ipynb', 'word2vec.ipynb', 'similarity-analogy.ipynb', 'word2vec-pretraining.ipynb', 'bert-pretraining.ipynb', 'approx-training.ipynb', 'bert.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_notation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_convolutional-neural-networks [] ['why-conv.ipynb', 'pooling.ipynb', 'conv-layer.ipynb', 'lenet.ipynb', 'index.ipynb', 'channels.ipynb', 'padding-and-strides.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_preface [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_installation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_computational-performance [] ['parameterserver.ipynb', 'multiple-gpus-concise.ipynb', 'hybridize.ipynb', 'my_mlp.pdiparams', 'async-computation.ipynb', 'hardware.ipynb', 'auto-parallelism.ipynb', 'my_mlp.pdmodel', 'index.ipynb', 'my_mlp.pdiparams.info', 'multiple-gpus.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_deep-learning-computation [] ['use-gpu.ipynb', 'model-construction.ipynb', 'custom-layer.ipynb', 'mydict', 'mlp.pdparams', 'x-file', 'deferred-init.ipynb', 'parameters.ipynb', 'index.ipynb', 'read-write.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_recurrent-modern [] ['deep-rnn.ipynb', 'lstm.ipynb', 'seq2seq.ipynb', 'bi-rnn.ipynb', 'machine-translation-and-dataset.ipynb', 'gru.ipynb', 'encoder-decoder.ipynb', 'index.ipynb', 'beam-search.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_attention-mechanisms [] ['nadaraya-waston.ipynb', 'attention-cues.ipynb', 'self-attention-and-positional-encoding.ipynb', 'bahdanau-attention.ipynb', 'multihead-attention.ipynb', 'transformer.ipynb', 'index.ipynb', 'attention-scoring-functions.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_natural-language-processing-applications [] ['natural-language-inference-bert.ipynb', 'natural-language-inference-attention.ipynb', 'sentiment-analysis-cnn.ipynb', 'finetuning-bert.ipynb', 'natural-language-inference-and-dataset.ipynb', 'sentiment-analysis-and-dataset.ipynb', 'index.ipynb', 'sentiment-analysis-rnn.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_optimization [] ['momentum.ipynb', 'rmsprop.ipynb', 'convexity.ipynb', 'optimization-intro.ipynb', 'lr-scheduler.ipynb', 'sgd.ipynb', 'adam.ipynb', 'minibatch-sgd.ipynb', 'adadelta.ipynb', 'gd.ipynb', 'index.ipynb', 'adagrad.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/paddle/chapter_introduction [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow ['chapter_appendix-tools-for-deep-learning', 'chapter_references', 'chapter_linear-networks', 'chapter_multilayer-perceptrons', 'chapter_convolutional-modern', 'chapter_preliminaries', 'chapter_computer-vision', 'chapter_recurrent-neural-networks', 'img', 'chapter_natural-language-processing-pretraining', 'chapter_notation', 'chapter_convolutional-neural-networks', 'chapter_preface', 'chapter_installation', 'chapter_computational-performance', 'chapter_deep-learning-computation', 'chapter_recurrent-modern', 'chapter_attention-mechanisms', 'chapter_natural-language-processing-applications', 'chapter_optimization', 'chapter_introduction'] ['d2l.bib', 'setup.py', 'TERMINOLOGY.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_appendix-tools-for-deep-learning [] ['contributing.ipynb', 'jupyter.ipynb', 'selecting-servers-gpus.ipynb', 'aws.ipynb', 'sagemaker.ipynb', 'd2l.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_references [] ['zreferences.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_linear-networks [] ['linear-regression-scratch.ipynb', 'linear-regression-concise.ipynb', 'softmax-regression.ipynb', 'softmax-regression-concise.ipynb', 'softmax-regression-scratch.ipynb', 'linear-regression.ipynb', 'image-classification-dataset.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_multilayer-perceptrons [] ['dropout.ipynb', 'submission.csv', 'mlp.ipynb', 'weight-decay.ipynb', 'mlp-concise.ipynb', 'mlp-scratch.ipynb', 'underfit-overfit.ipynb', 'kaggle-house-price.ipynb', 'backprop.ipynb', 'numerical-stability-and-init.ipynb', 'environment.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_convolutional-modern [] ['vgg.ipynb', 'densenet.ipynb', 'googlenet.ipynb', 'nin.ipynb', 'batch-norm.ipynb', 'alexnet.ipynb', 'resnet.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_preliminaries [] ['calculus.ipynb', 'ndarray.ipynb', 'linear-algebra.ipynb', 'probability.ipynb', 'pandas.ipynb', 'index.ipynb', 'lookup-api.ipynb', 'autograd.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_computer-vision [] ['fcn.ipynb', 'image-augmentation.ipynb', 'transposed-conv.ipynb', 'rcnn.ipynb', 'kaggle-dog.ipynb', 'ssd.ipynb', 'neural-style.ipynb', 'multiscale-object-detection.ipynb', 'fine-tuning.ipynb', 'object-detection-dataset.ipynb', 'bounding-box.ipynb', 'anchor.ipynb', 'index.ipynb', 'kaggle-cifar10.ipynb', 'semantic-segmentation-and-dataset.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_recurrent-neural-networks [] ['language-models-and-dataset.ipynb', 'text-preprocessing.ipynb', 'rnn.ipynb', 'sequence.ipynb', 'rnn-concise.ipynb', 'rnn-scratch.ipynb', 'bptt.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/img ['frontends'] ['rainier.jpg', 'chain-net1.svg', 'falsesharing.svg', 'bert-one-seq.svg', 'seq2seq-details.svg', 'data-collection.svg', 'neon128.svg', 'statistical-significance.svg', 'rec-mf.svg', 'conv-multi-in.svg', 'cat-dog-train.svg', 'git-newpr.png', 'mask-rcnn.svg', 'negSecDer.svg', 'softmaxreg.svg', 'eye-coffee.svg', 'ml-loop.svg', 'textcnn.svg', 'death-cap.jpg', 'neural-style.svg', 's2s-prob2.svg', 'chain-net2.svg', 'supervised-learning.svg', 'git-clone.png', 'data-parallel.svg', 'git-fork.png', 'filters.png', 'tensorcore.jpg', 'transformer.svg', 'sagemaker.png', 'mlp.svg', 's2s-prob1.svg', 'bert-input.svg', 'skip-gram.svg', 'qkv.svg', 'copyto.svg', 'seq2seq-attention.svg', 'inception-full.svg', 'lstm-0.svg', 'rec-intro.svg', 'trans_conv_stride2.svg', 'frontends.svg', 'waldo-mask.jpg', 'house-pricing.png', 'seq2seq-predict.svg', 'conv1d-2d.svg', 'gan.svg', 'rl-environment.svg', 'dog2.jpg', 'conv-1x1.svg', 'p2x.png', 'rnn.svg', 'lstm-1.svg', 'proj-vec.svg', 'ssd.svg', 'flopsvsprice.svg', 'lstm-3.svg', 'rec-deepfm.svg', 'projections.svg', 'nvlink-twoloop.svg', 'nin.svg', 'asyncgraph.svg', 'dog1.jpg', 'pikachu.jpg', 'roi.svg', 'lstm-2.svg', 'birnn.svg', 'chmod.png', 'r-cnn.svg', 'lenet.svg', 'resnet-block.svg', 'cnn-rnn-self-attention.svg', 'cat1.jpg', 'bert-tagging.svg', 'cuda101.png', 'jupyter06.png', 'kaggle.png', 'densenet.svg', 'trans_conv.svg', 'style-transfer.svg', 'popvssoda.png', 'faster-rcnn.svg', 'conv-pad.svg', 'capacity_vs_error.svg', 'sequence-model.svg', 'attention.svg', 'seq2seq-attention-details.svg', 'computegraph.svg', 'cat2.jpg', 'cat-dog-pixels.png', 'colab.png', 'jupyter05.png', 'ec2.png', 'conv1d-channel.svg', 'alexnet-original.svg', 'frontends.png', 'jupyter04.png', 'sagemaker-create.png', 'cat3.jpg', 'vec-add.svg', 'seq2seq.svg', 'jupyter.png', 'deeplearning-amazon.jpg', 'aws.png', 'vgg.svg', 'launching.png', 'sagemaker-create-3-pytorch.png', 'sagemaker-open.png', 'nlp-map-sa-rnn.svg', 'ps-distributed.svg', 'jupyter00.png', 'jupyter01.png', 'nlp-map-nli-attention.svg', 'conv1d.svg', 'fit-linreg.svg', 'timemachine-5gram.svg', 'wattvsprice.svg', 'neural-style.jpg', 'attention-output.svg', 'where-wally-walker-books.jpg', 'turing-processing-block.png', 'contribute.svg', 'eye-coffee.png', 'anchor-label.svg', 'densenet-block.svg', 'kaggle-cifar10.png', 'jupyter03.png', 'jupyter02.png', 'splitting.svg', 'grid-points.svg', 'threading.svg', 'blocks.svg', 'connect.png', 'dropout2.svg', 'hi-softmax.svg', 'wake-word.svg', 'mutual-information.svg', 'nvlink.svg', 'rnn-train.svg', 'singleneuron.svg', 'catdog.jpg', 'lang-model-data.svg', 'lenet-vert.svg', 'conv-stride.svg', 'nlp-map-pretrain.svg', 'par-vec.svg', 'mobo-symbol.svg', 'resnet18.svg', 'add_norm.svg', 'residual-block.svg', 'zeroSecDer.svg', 'edit-file.png', 'cbow.svg', 'posSecDer.svg', 'sagemaker-create-3.png', 'inception.svg', 'git-createpr.png', 'pacman.svg', 'truncated-bptt.svg', 'limits.png', 'sagemaker-create-2.png', 'hmm.svg', 'sagemaker-terminal.png', 'eye-book.png', 'rec-neumf.svg', 'ftse100.png', 'rect-trans.svg', 'nlp-map-nli-bert.svg', 'finetune.svg', 'twogpu.svg', 'rec-caser.svg', 'capacity-vs-error.svg', 'alexnet.svg', 'Marginal.svg', 'convex-intersect.svg', 'ubuntu-new.png', 'Neuron.svg', 'kaggle-submit2.png', 'fcn.svg', 'ringsync.svg', 'ps-multips.svg', 'nlp-map-sa-cnn.svg', 'rec-seq-data.svg', 'rec-ranking.svg', 'functionclasses.svg', 'sagemaker-stop.png', 'nonconvex.svg', 'book-org.svg', 'elmo-gpt-bert.svg', 'ps-multimachine.svg', 'a77.svg', 'singlelayer.svg', 'pooling.svg', 'banana.jpg', 'falseshare.svg', 'bert-two-seqs.svg', 'self-attention.svg', 'encoder-decoder.svg', 'nlp-map-app.svg', 'grid-transform.svg', 'multi-head-attention.svg', 'deep-rnn.svg', 'grid-transform-filled.svg', 'eye-book.svg', 'sub-area.svg', 'nin-compare.svg', 'polygon-circle.svg', 'disk.png', 'space-division-3d.svg', 'nli-attention.svg', 'sum-order.svg', 'beam-search.svg', 'correlation.svg', 'nli_attention.svg', 'colab-2.png', 'forward.svg', 'latencynumbers.png', 'rnn-bptt.svg', 'gru-2.svg', 'iou.svg', 'turing.png', 'speech.png', 'koebel.jpg', 'gru-3.svg', 'fast-rcnn.svg', 'git-forked.png', 'sagemaker-create-3-tensorflow.png', 'space-division.svg', 'cat-dog-test.svg', 'vec-angle.svg', 'stackedanimals.png', 'ps.svg', 'segmentation.svg', 'kaggle-dog.jpg', 'keypair.png', 'gru-1.svg', 'autumn-oak.jpg', 'bw-hierarchy.svg', 'skylake.svg', 'bert-qa.svg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/img/frontends [] ['Canvas 1.svg', 'image10.tiff', 'image8.tiff', 'image4.tiff', 'image5.pdf', 'image3.tiff', 'image2.tiff']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_natural-language-processing-pretraining [] ['glove.ipynb', 'word-embedding-dataset.ipynb', 'bert-dataset.ipynb', 'subword-embedding.ipynb', 'word2vec.ipynb', 'similarity-analogy.ipynb', 'word2vec-pretraining.ipynb', 'bert-pretraining.ipynb', 'approx-training.ipynb', 'bert.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_notation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_convolutional-neural-networks [] ['why-conv.ipynb', 'pooling.ipynb', 'conv-layer.ipynb', 'lenet.ipynb', 'index.ipynb', 'channels.ipynb', 'padding-and-strides.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_preface [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_installation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_computational-performance ['my_mlp'] ['parameterserver.ipynb', 'multiple-gpus-concise.ipynb', 'hybridize.ipynb', 'async-computation.ipynb', 'hardware.ipynb', 'auto-parallelism.ipynb', 'index.ipynb', 'multiple-gpus.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_computational-performance/my_mlp ['variables'] ['saved_model.pb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_computational-performance/my_mlp/variables [] ['variables.data-00000-of-00001', 'variables.index']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_deep-learning-computation [] ['use-gpu.ipynb', 'model-construction.ipynb', 'checkpoint', 'custom-layer.ipynb', 'mlp.params.index', 'deferred-init.ipynb', 'parameters.ipynb', 'xy-files.npy', 'x-file.npy', 'index.ipynb', 'mydict.npy', 'mlp.params.data-00000-of-00001', 'read-write.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_recurrent-modern [] ['deep-rnn.ipynb', 'lstm.ipynb', 'seq2seq.ipynb', 'bi-rnn.ipynb', 'machine-translation-and-dataset.ipynb', 'gru.ipynb', 'encoder-decoder.ipynb', 'index.ipynb', 'beam-search.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_attention-mechanisms [] ['nadaraya-waston.ipynb', 'attention-cues.ipynb', 'self-attention-and-positional-encoding.ipynb', 'bahdanau-attention.ipynb', 'multihead-attention.ipynb', 'transformer.ipynb', 'index.ipynb', 'attention-scoring-functions.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_natural-language-processing-applications [] ['natural-language-inference-bert.ipynb', 'natural-language-inference-attention.ipynb', 'sentiment-analysis-cnn.ipynb', 'finetuning-bert.ipynb', 'natural-language-inference-and-dataset.ipynb', 'sentiment-analysis-and-dataset.ipynb', 'index.ipynb', 'sentiment-analysis-rnn.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_optimization [] ['momentum.ipynb', 'rmsprop.ipynb', 'convexity.ipynb', 'optimization-intro.ipynb', 'lr-scheduler.ipynb', 'sgd.ipynb', 'adam.ipynb', 'minibatch-sgd.ipynb', 'adadelta.ipynb', 'gd.ipynb', 'index.ipynb', 'adagrad.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/tensorflow/chapter_introduction [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch ['chapter_appendix-tools-for-deep-learning', 'chapter_references', 'chapter_linear-networks', 'chapter_multilayer-perceptrons', 'chapter_convolutional-modern', 'chapter_preliminaries', 'chapter_computer-vision', 'chapter_recurrent-neural-networks', 'img', 'chapter_natural-language-processing-pretraining', 'chapter_notation', 'chapter_convolutional-neural-networks', 'chapter_preface', 'chapter_installation', 'chapter_computational-performance', 'chapter_deep-learning-computation', 'chapter_recurrent-modern', 'chapter_attention-mechanisms', 'chapter_natural-language-processing-applications', 'chapter_optimization', 'chapter_introduction'] ['.DS_Store', 'd2l.bib', 'setup.py', 'TERMINOLOGY.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_appendix-tools-for-deep-learning [] ['contributing.ipynb', 'jupyter.ipynb', 'selecting-servers-gpus.ipynb', 'aws.ipynb', 'sagemaker.ipynb', 'd2l.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_references [] ['zreferences.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_linear-networks [] ['linear-regression-scratch.ipynb', 'linear-regression-concise.ipynb', 'softmax-regression.ipynb', 'softmax-regression-concise.ipynb', 'softmax-regression-scratch.ipynb', 'linear-regression.ipynb', 'image-classification-dataset.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_multilayer-perceptrons [] ['dropout.ipynb', 'submission.csv', 'mlp.ipynb', 'weight-decay.ipynb', 'mlp-concise.ipynb', 'mlp-scratch.ipynb', 'underfit-overfit.ipynb', 'kaggle-house-price.ipynb', 'backprop.ipynb', 'numerical-stability-and-init.ipynb', 'environment.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_convolutional-modern [] ['vgg.ipynb', 'densenet.ipynb', 'googlenet.ipynb', 'nin.ipynb', 'batch-norm.ipynb', 'alexnet.ipynb', 'resnet.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_preliminaries [] ['calculus.ipynb', 'ndarray.ipynb', 'linear-algebra.ipynb', 'probability.ipynb', 'pandas.ipynb', 'index.ipynb', 'lookup-api.ipynb', 'autograd.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_computer-vision [] ['fcn.ipynb', 'submission.csv', 'image-augmentation.ipynb', 'transposed-conv.ipynb', 'rcnn.ipynb', 'kaggle-dog.ipynb', 'ssd.ipynb', 'neural-style.ipynb', 'multiscale-object-detection.ipynb', 'fine-tuning.ipynb', 'object-detection-dataset.ipynb', 'bounding-box.ipynb', 'anchor.ipynb', 'index.ipynb', 'kaggle-cifar10.ipynb', 'semantic-segmentation-and-dataset.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_recurrent-neural-networks [] ['language-models-and-dataset.ipynb', 'text-preprocessing.ipynb', 'rnn.ipynb', 'sequence.ipynb', 'rnn-concise.ipynb', 'rnn-scratch.ipynb', 'bptt.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/img ['frontends'] ['rainier.jpg', 'chain-net1.svg', 'falsesharing.svg', 'bert-one-seq.svg', 'seq2seq-details.svg', 'data-collection.svg', 'neon128.svg', 'statistical-significance.svg', 'rec-mf.svg', 'conv-multi-in.svg', 'cat-dog-train.svg', 'git-newpr.png', 'mask-rcnn.svg', 'negSecDer.svg', 'softmaxreg.svg', 'eye-coffee.svg', 'ml-loop.svg', 'textcnn.svg', 'death-cap.jpg', 'neural-style.svg', 's2s-prob2.svg', 'chain-net2.svg', 'supervised-learning.svg', 'git-clone.png', 'data-parallel.svg', 'git-fork.png', 'filters.png', 'tensorcore.jpg', 'transformer.svg', 'sagemaker.png', 'mlp.svg', 's2s-prob1.svg', 'bert-input.svg', 'skip-gram.svg', 'qkv.svg', 'copyto.svg', 'seq2seq-attention.svg', 'inception-full.svg', 'lstm-0.svg', 'rec-intro.svg', 'trans_conv_stride2.svg', 'frontends.svg', 'waldo-mask.jpg', 'house-pricing.png', 'seq2seq-predict.svg', 'conv1d-2d.svg', 'gan.svg', 'rl-environment.svg', 'dog2.jpg', 'conv-1x1.svg', 'p2x.png', 'rnn.svg', 'lstm-1.svg', 'proj-vec.svg', 'ssd.svg', 'flopsvsprice.svg', 'lstm-3.svg', 'rec-deepfm.svg', 'projections.svg', 'nvlink-twoloop.svg', 'nin.svg', 'asyncgraph.svg', 'dog1.jpg', 'pikachu.jpg', 'roi.svg', 'lstm-2.svg', 'birnn.svg', 'chmod.png', 'r-cnn.svg', 'lenet.svg', 'resnet-block.svg', 'cnn-rnn-self-attention.svg', 'cat1.jpg', 'bert-tagging.svg', 'cuda101.png', 'jupyter06.png', 'kaggle.png', 'densenet.svg', 'trans_conv.svg', 'style-transfer.svg', 'popvssoda.png', 'faster-rcnn.svg', 'conv-pad.svg', 'capacity_vs_error.svg', 'sequence-model.svg', 'attention.svg', 'seq2seq-attention-details.svg', 'computegraph.svg', 'cat2.jpg', 'cat-dog-pixels.png', 'colab.png', 'jupyter05.png', 'ec2.png', 'conv1d-channel.svg', 'alexnet-original.svg', 'frontends.png', 'jupyter04.png', 'sagemaker-create.png', 'cat3.jpg', 'vec-add.svg', 'seq2seq.svg', 'jupyter.png', 'deeplearning-amazon.jpg', 'aws.png', 'vgg.svg', 'launching.png', 'sagemaker-create-3-pytorch.png', 'sagemaker-open.png', 'nlp-map-sa-rnn.svg', 'ps-distributed.svg', 'jupyter00.png', 'jupyter01.png', 'nlp-map-nli-attention.svg', 'conv1d.svg', 'fit-linreg.svg', 'timemachine-5gram.svg', 'wattvsprice.svg', 'neural-style.jpg', 'attention-output.svg', 'where-wally-walker-books.jpg', 'turing-processing-block.png', 'contribute.svg', 'eye-coffee.png', 'anchor-label.svg', 'densenet-block.svg', 'kaggle-cifar10.png', 'jupyter03.png', 'jupyter02.png', 'splitting.svg', 'grid-points.svg', 'threading.svg', 'blocks.svg', 'connect.png', 'dropout2.svg', 'hi-softmax.svg', 'wake-word.svg', 'mutual-information.svg', 'nvlink.svg', 'rnn-train.svg', 'singleneuron.svg', 'catdog.jpg', 'lang-model-data.svg', 'lenet-vert.svg', 'conv-stride.svg', 'nlp-map-pretrain.svg', 'par-vec.svg', 'mobo-symbol.svg', 'resnet18.svg', 'add_norm.svg', 'residual-block.svg', 'zeroSecDer.svg', 'edit-file.png', 'cbow.svg', 'posSecDer.svg', 'sagemaker-create-3.png', 'inception.svg', 'git-createpr.png', 'pacman.svg', 'truncated-bptt.svg', 'limits.png', 'sagemaker-create-2.png', 'hmm.svg', 'sagemaker-terminal.png', 'eye-book.png', 'rec-neumf.svg', 'ftse100.png', 'rect-trans.svg', 'nlp-map-nli-bert.svg', 'finetune.svg', 'twogpu.svg', 'rec-caser.svg', 'capacity-vs-error.svg', 'alexnet.svg', 'Marginal.svg', 'convex-intersect.svg', 'ubuntu-new.png', 'Neuron.svg', 'kaggle-submit2.png', 'fcn.svg', 'ringsync.svg', 'ps-multips.svg', 'nlp-map-sa-cnn.svg', 'rec-seq-data.svg', 'rec-ranking.svg', 'functionclasses.svg', 'sagemaker-stop.png', 'nonconvex.svg', 'book-org.svg', 'elmo-gpt-bert.svg', 'ps-multimachine.svg', 'a77.svg', 'singlelayer.svg', 'pooling.svg', 'banana.jpg', 'falseshare.svg', 'bert-two-seqs.svg', 'self-attention.svg', 'encoder-decoder.svg', 'nlp-map-app.svg', 'grid-transform.svg', 'multi-head-attention.svg', 'deep-rnn.svg', 'grid-transform-filled.svg', 'eye-book.svg', 'sub-area.svg', 'nin-compare.svg', 'polygon-circle.svg', 'disk.png', 'space-division-3d.svg', 'nli-attention.svg', 'sum-order.svg', 'beam-search.svg', 'correlation.svg', 'nli_attention.svg', 'colab-2.png', 'forward.svg', 'latencynumbers.png', 'rnn-bptt.svg', 'gru-2.svg', 'iou.svg', 'turing.png', 'speech.png', 'koebel.jpg', 'gru-3.svg', 'fast-rcnn.svg', 'git-forked.png', 'sagemaker-create-3-tensorflow.png', 'space-division.svg', 'cat-dog-test.svg', 'vec-angle.svg', 'stackedanimals.png', 'ps.svg', 'segmentation.svg', 'kaggle-dog.jpg', 'keypair.png', 'gru-1.svg', 'autumn-oak.jpg', 'bw-hierarchy.svg', 'skylake.svg', 'bert-qa.svg']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/img/frontends [] ['Canvas 1.svg', 'image10.tiff', 'image8.tiff', 'image4.tiff', 'image5.pdf', 'image3.tiff', 'image2.tiff']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_natural-language-processing-pretraining [] ['glove.ipynb', 'word-embedding-dataset.ipynb', 'bert-dataset.ipynb', 'subword-embedding.ipynb', 'word2vec.ipynb', 'similarity-analogy.ipynb', 'word2vec-pretraining.ipynb', 'bert-pretraining.ipynb', 'approx-training.ipynb', 'bert.ipynb', 'index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_notation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_convolutional-neural-networks [] ['why-conv.ipynb', 'pooling.ipynb', 'conv-layer.ipynb', 'lenet.ipynb', 'index.ipynb', 'channels.ipynb', 'padding-and-strides.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_preface [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_installation [] ['index.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_computational-performance [] ['parameterserver.ipynb', 'multiple-gpus-concise.ipynb', 'hybridize.ipynb', 'my_mlp', 'async-computation.ipynb', 'hardware.ipynb', 'auto-parallelism.ipynb', 'index.ipynb', 'multiple-gpus.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_deep-learning-computation [] ['use-gpu.ipynb', 'model-construction.ipynb', 'x-files', 'custom-layer.ipynb', 'mydict', 'mlp.params', 'x-file', 'deferred-init.ipynb', 'parameters.ipynb', 'index.ipynb', 'read-write.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_recurrent-modern [] ['deep-rnn.ipynb', 'lstm.ipynb', 'seq2seq.ipynb', 'bi-rnn.ipynb', 'machine-translation-and-dataset.ipynb', 'gru.ipynb', 'encoder-decoder.ipynb', 'index.ipynb', 'beam-search.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_attention-mechanisms [] ['nadaraya-waston.ipynb', 'attention-cues.ipynb', 'self-attention-and-positional-encoding.ipynb', 'bahdanau-attention.ipynb', 'multihead-attention.ipynb', 'transformer.ipynb', 'index.ipynb', 'attention-scoring-functions.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_natural-language-processing-applications [] ['natural-language-inference-bert.ipynb', 'natural-language-inference-attention.ipynb', 'sentiment-analysis-cnn.ipynb', 'finetuning-bert.ipynb', 'natural-language-inference-and-dataset.ipynb', 'sentiment-analysis-and-dataset.ipynb', 'index.ipynb', 'sentiment-analysis-rnn.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_optimization [] ['momentum.ipynb', 'rmsprop.ipynb', 'convexity.ipynb', 'optimization-intro.ipynb', 'lr-scheduler.ipynb', 'sgd.ipynb', 'adam.ipynb', 'minibatch-sgd.ipynb', 'adadelta.ipynb', 'gd.ipynb', 'index.ipynb', 'adagrad.ipynb']\n",
      "/Users/liushiwen/Desktop/大四上/機器學習導論/d2l-zh/pytorch/chapter_introduction [] ['index.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "walking = os.walk('/Users/liushiwen/Desktop/大四上/機器學習導論')\n",
    "for a,b,c in walking:\n",
    "    print( a, b, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
