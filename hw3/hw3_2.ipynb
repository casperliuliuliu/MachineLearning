{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "data = pd.read_csv('./HW3 附件/HW3_creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, y_pred):\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "    # Calculate recall (sensitivity)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # Calculate F1 score (harmonic mean of precision and recall)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    # Calculate ROC AUC (Receiver Operating Characteristic Area Under the Curve)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "target_column = 'Class'\n",
    "test_size = 0.3\n",
    "random_state = 42\n",
    "\n",
    "# Seperate features and target\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In all the data:\n",
      "Class 0: 28432\n",
      "Class 1: 492\n",
      "\n",
      "In Train data:\n",
      "Class 0: 19909\n",
      "Class 1: 337\n",
      "\n",
      "In Val data:\n",
      "Class 0: 8523\n",
      "Class 1: 155\n"
     ]
    }
   ],
   "source": [
    "# Checking the data distribution\n",
    "print(\"In all the data:\")\n",
    "print(f\"Class 0: {(y == 0).sum()}\")\n",
    "print(f\"Class 1: {(y == 1).sum()}\")\n",
    "print('')\n",
    "print(\"In Train data:\")\n",
    "print(f\"Class 0: {(y_train == 0).sum()}\")\n",
    "print(f\"Class 1: {(y_train == 1).sum()}\")\n",
    "print('')\n",
    "print(\"In Val data:\")\n",
    "print(f\"Class 0: {(y_val == 0).sum()}\")\n",
    "print(f\"Class 1: {(y_val == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Part\n",
    "\n",
    "Class 0: 28432\n",
    "Class 1: 492\n",
    "\n",
    "In Train data:\n",
    "Class 0: 19909\n",
    "Class 1: 337\n",
    "\n",
    "In Val data:\n",
    "Class 0: 8523\n",
    "Class 1: 155\n",
    "\n",
    "With the data distribution of ['Class'], we can clearly see class 0 is more than 57 times of class 1.\n",
    "The data is highly imbalance, we have to make use of recall or data augmented to validate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20246, 30)\n",
      "(8678, 30)\n",
      "(28924, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19909     0]\n",
      " [    0   337]]\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "[[8503   20]\n",
      " [  28  127]]\n",
      "Accuracy: 0.9945\n",
      "Precision: 0.8639\n",
      "Recall: 0.8194\n",
      "F1 Score: 0.8411\n",
      "ROC AUC: 0.9085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "def test_model(classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # Predict on the training data and calculate accuracy\n",
    "    y_pred = classifier.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    confusion = confusion_matrix(y_train, y_pred)\n",
    "    print(confusion)\n",
    "    metrics(y_train, y_pred)\n",
    "\n",
    "\n",
    "    # Predict on the validation data and calculate accuracy\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    confusion = confusion_matrix(y_val, y_pred)\n",
    "    print(confusion)\n",
    "    metrics(y_val, y_pred)\n",
    "\n",
    "test_model(decision_tree_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19909     0]\n",
      " [    0   337]]\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "[[8501   22]\n",
      " [  19  136]]\n",
      "Accuracy: 0.9953\n",
      "Precision: 0.8608\n",
      "Recall: 0.8774\n",
      "F1 Score: 0.8690\n",
      "ROC AUC: 0.9374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weighted_tree_classifier = DecisionTreeClassifier(class_weight={0: 58, 1: 1}, random_state=42)\n",
    "test_model(weighted_tree_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "Accuracy: 0.9945\n",
      "Precision: 0.8639\n",
      "Recall: 0.8194\n",
      "F1 Score: 0.8411\n",
      "ROC AUC: 0.9085\n",
      "\n",
      "After resampling based on SMOTE:\n",
      "Accuracy: 0.9892\n",
      "Precision: 0.6533\n",
      "Recall: 0.8387\n",
      "F1 Score: 0.7345\n",
      "ROC AUC: 0.9153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Resample data using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fitting model on original data\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fitting model on resampled data from SMOTE\n",
    "decision_tree_classifier_resampled = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_classifier_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict with original data\n",
    "y_pred = decision_tree_classifier.predict(X_val)\n",
    "print(\"Original:\")\n",
    "metrics(y_val, y_pred)\n",
    "\n",
    "# Predict with resampled data\n",
    "y_pred_resampled = decision_tree_classifier_resampled.predict(X_val)\n",
    "print(\"After resampling based on SMOTE:\")\n",
    "metrics(y_val, y_pred_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost:\n",
      "Accuracy: 0.9975\n",
      "Precision: 0.9926\n",
      "Recall: 0.8645\n",
      "F1 Score: 0.9241\n",
      "ROC AUC: 0.9322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "print(\"XGBoost:\")\n",
    "metrics(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resampling based on SMOTE:\n",
      "Accuracy: 0.9968\n",
      "Precision: 0.9262\n",
      "Recall: 0.8903\n",
      "F1 Score: 0.9079\n",
      "ROC AUC: 0.9445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model_r = xgb.XGBClassifier()\n",
    "xgb_model_r.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_resampled = xgb_model_r.predict(X_val)\n",
    "print(\"After resampling based on SMOTE:\")\n",
    "metrics(y_val, y_pred_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After resampling based on SMOTE:\n",
      "Accuracy: 0.9968\n",
      "Precision: 0.9262\n",
      "Recall: 0.8903\n",
      "F1 Score: 0.9079\n",
      "ROC AUC: 0.9445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model_ro = xgb.XGBClassifier()\n",
    "xgb_model_ro.fit(X_train, y_train)\n",
    "xgb_model_ro.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_resampled = xgb_model_ro.predict(X_val)\n",
    "print(\"After resampling based on SMOTE:\")\n",
    "metrics(y_val, y_pred_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
