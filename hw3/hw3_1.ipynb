{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "data = pd.read_csv('./HW3 附件/HW2_hr-analytics_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "# check nan\n",
    "def check_nan(df):\n",
    "    return df.isna().any().any()\n",
    "\n",
    "def onehot_encoding(df, column_name, show=True):\n",
    "    df_encoded = pd.get_dummies(df, columns=[column_name], prefix=[column_name])\n",
    "    if show:\n",
    "        print(f\"After operating [\\'{column_name}\\']. {df.shape} -> {df_encoded.shape}\")\n",
    "    return df_encoded\n",
    "\n",
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    global filename\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "        \n",
    "def check_non_numeric_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Check if any value in the specified column is not int or float.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to check.\n",
    "    column_name (str): The name of the column to check.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if any non-numeric value is found, False otherwise.\n",
    "    \"\"\"\n",
    "    # Get the specified column\n",
    "    column = df[column_name]\n",
    "\n",
    "    # Check if any value is not int or float\n",
    "    non_numeric_values = column[~column.apply(lambda x: isinstance(x, (int, float)))]\n",
    "    \n",
    "    return not non_numeric_values.empty\n",
    "\n",
    "def count_unique_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Count the number of unique values in the specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to check.\n",
    "    column_name (str): The name of the column to count unique values for.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of unique values.\n",
    "    \"\"\"\n",
    "    unique_values = df[column_name].nunique()\n",
    "    return unique_values\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "    # Calculate recall (sensitivity)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # Calculate F1 score (harmonic mean of precision and recall)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    # Calculate ROC AUC (Receiver Operating Characteristic Area Under the Curve)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing onehot encoding on col: []\n",
      "With Train Data, the metrics of model:\n",
      "Confusion matrix:\n",
      "[[6090    0]\n",
      " [   0 1910]]\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "With Val Data, the metrics of model:\n",
      "Confusion matrix:\n",
      "[[747  12]\n",
      " [ 13 228]]\n",
      "Accuracy: 0.9750\n",
      "Precision: 0.9500\n",
      "Recall: 0.9461\n",
      "F1 Score: 0.9480\n",
      "ROC AUC: 0.9651\n",
      "\n",
      "With Val Data, the metrics of model:\n",
      "Confusion matrix:\n",
      "[[743  16]\n",
      " [ 12 229]]\n",
      "Accuracy: 0.9720\n",
      "Precision: 0.9347\n",
      "Recall: 0.9502\n",
      "F1 Score: 0.9424\n",
      "ROC AUC: 0.9646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_not_num = []\n",
    "for col in df.columns:\n",
    "    if check_non_numeric_values(df, col):\n",
    "        col_not_num.append(col)\n",
    "\n",
    "print(f\"Doing onehot encoding on col: {col_not_num}\")\n",
    "for col in col_not_num:\n",
    "    df = onehot_encoding(df, col)\n",
    "\n",
    "target_column = 'left'\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "trans = True\n",
    "if trans: # 956 -> 957\n",
    "    scaler = StandardScaler()\n",
    "    df['average_montly_hours'] = scaler.fit_transform(df[['average_montly_hours']])\n",
    "    # df['time_spend_company'] = scaler.fit_transform(df[['time_spend_company']])\n",
    "\n",
    "\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the Decision Tree classifier to the training data\n",
    "decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Train Data, the metrics of model:\n",
      "Confusion matrix:\n",
      "[[6090    0]\n",
      " [   0 1910]]\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "With Val Data, the metrics of model:\n",
      "Confusion matrix:\n",
      "[[747  12]\n",
      " [ 13 228]]\n",
      "Accuracy: 0.9750\n",
      "Precision: 0.9500\n",
      "Recall: 0.9461\n",
      "F1 Score: 0.9480\n",
      "ROC AUC: 0.9651\n",
      "\n",
      "With Test Data, the metrics of model:\n",
      "Confusion matrix:\n",
      "[[743  16]\n",
      " [ 12 229]]\n",
      "Accuracy: 0.9720\n",
      "Precision: 0.9347\n",
      "Recall: 0.9502\n",
      "F1 Score: 0.9424\n",
      "ROC AUC: 0.9646\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the training data and calculate accuracy\n",
    "print(\"With Train Data, the metrics of model:\")\n",
    "y_pred = decision_tree_classifier.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "confusion = confusion_matrix(y_train, y_pred)\n",
    "print(f\"Confusion matrix:\\n{confusion}\")\n",
    "metrics(y_train, y_pred)\n",
    "\n",
    "# Predict on the validation data and calculate accuracy\n",
    "print(\"With Val Data, the metrics of model:\")\n",
    "y_pred = decision_tree_classifier.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "print(f\"Confusion matrix:\\n{confusion}\")\n",
    "metrics(y_val, y_pred)\n",
    "\n",
    "# Predict on the tesing data and calculate accuracy\n",
    "print(\"With Test Data, the metrics of model:\")\n",
    "y_pred = decision_tree_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion matrix:\\n{confusion}\")\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of dropping ['satisfaction_level'] = 0.957\n",
      "The accuracy of dropping ['last_evaluation'] = 0.975\n",
      "The accuracy of dropping ['number_project'] = 0.97\n",
      "The accuracy of dropping ['average_montly_hours'] = 0.969\n",
      "The accuracy of dropping ['time_spend_company'] = 0.962\n",
      "The accuracy of dropping ['Work_accident'] = 0.973\n",
      "The accuracy of dropping ['promotion_last_5years'] = 0.974\n",
      "The accuracy of dropping ['sales'] = 0.976\n",
      "The accuracy of dropping ['salary'] = 0.971\n"
     ]
    }
   ],
   "source": [
    "def test_importance(df):\n",
    "    col_not_num = []\n",
    "    for col in df.columns:\n",
    "        if check_non_numeric_values(df, col):\n",
    "            col_not_num.append(col)\n",
    "\n",
    "    for col in col_not_num:\n",
    "        df = onehot_encoding(df, col, False)\n",
    "\n",
    "    target_column = 'left'\n",
    "    test_size = 0.2\n",
    "    random_state = 42\n",
    "\n",
    "    trans = True\n",
    "    if trans: # 956 -> 957\n",
    "        scaler = StandardScaler()\n",
    "        if 'average_montly_hours' in df.columns:\n",
    "            df['average_montly_hours'] = scaler.fit_transform(df[['average_montly_hours']])\n",
    "        # df['time_spend_company'] = scaler.fit_transform(df[['time_spend_company']])\n",
    "\n",
    "\n",
    "\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state)\n",
    "\n",
    "    # Create a Decision Tree classifier\n",
    "    decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "    # Fit the Decision Tree classifier to the training data\n",
    "    decision_tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the training data and calculate accuracy\n",
    "    y_pred = decision_tree_classifier.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "    # Predict on the validation data and calculate accuracy\n",
    "    y_pred = decision_tree_classifier.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "col_data = data.copy()\n",
    "# print(col_data.columns)\n",
    "score = {}\n",
    "for ii in col_data.columns.drop('left'):\n",
    "    temp = data.copy()\n",
    "    temp = temp.drop(columns=[ii])\n",
    "    acc = test_importance(temp)\n",
    "    score[ii] = acc\n",
    "    print(f\"The accuracy of dropping [\\'{ii}\\'] = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('satisfaction_level', 0.957),\n",
       " ('time_spend_company', 0.962),\n",
       " ('average_montly_hours', 0.969),\n",
       " ('number_project', 0.97),\n",
       " ('salary', 0.971),\n",
       " ('Work_accident', 0.973),\n",
       " ('promotion_last_5years', 0.974),\n",
       " ('last_evaluation', 0.975),\n",
       " ('sales', 0.976)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(score.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our answer to question 5:\n",
    "In order to find out the top 2 important features in the data, we decided to remove feature one by one, and record the val accuracy after removal.\n",
    "\n",
    "* RESULT:\n",
    "[('satisfaction_level', 0.957),\n",
    " ('time_spend_company', 0.962),\n",
    " ('average_montly_hours', 0.969),\n",
    " ('number_project', 0.97),\n",
    " ('salary', 0.971),\n",
    " ('Work_accident', 0.973),\n",
    " ('promotion_last_5years', 0.974),\n",
    " ('last_evaluation', 0.975),\n",
    " ('sales', 0.976)]\n",
    "\n",
    "According to the result, we can observe that **['satisfaction_level']** and **['time_spend_company']** decreases the val accuracy the most.\n",
    "This means **['satisfaction_level']** and **['time_spend_company']** are the top 2 important features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By creating a VotingClassifier with **('lasso2', lasso_classifier2)** **('ridge3', ridge_classifier3)**\n",
    "We get in training data:\n",
    "* Confusion matrix\n",
    "    [[6010   80]\n",
    "    [ 181 1729]]\n",
    "* Precision: 0.9558\n",
    "* Recall (Sensitivity): 0.9052\n",
    "* F1 Score: 0.9298\n",
    "* AUROC: 0.9460\n",
    "\n",
    "We get in validating data:\n",
    "* Confusion matrix\n",
    "    [[743  16]\n",
    "    [ 27 214]]\n",
    "* Accuracy: 0.9570\n",
    "* Precision: 0.9304\n",
    "* Recall (Sensitivity): 0.8880\n",
    "* F1 Score: 0.9087\n",
    "* AUROC: 0.9334\n",
    "\n",
    "### Comparing to decision_tree_classifier\n",
    "We get in training data:\n",
    "* Confusion matrix:\n",
    "    [[6090    0]\n",
    "    [   0 1910]]\n",
    "* Accuracy: 1.0000\n",
    "* Precision: 1.0000\n",
    "* Recall: 1.0000\n",
    "* F1 Score: 1.0000\n",
    "* AUROC: 1.0000\n",
    "\n",
    "We get in validating data:\n",
    "* Confusion matrix:\n",
    "    [[750   9]\n",
    "    [ 13 228]]\n",
    "* Accuracy: 0.9780\n",
    "* Precision: 0.9620\n",
    "* Recall: 0.9461\n",
    "* F1 Score: 0.9540\n",
    "* AUROC: 0.9671\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our answer to question 7:\n",
    "In training data and validating data, we can see that decision tree classifier has a overall victory on the metrics.\n",
    "Combining with the result of linear regression without any data transform or polynomial feature, we could know that most part of the data is non-linear.\n",
    "Decision tree could better fit in data that has more complicate relationship, which results in performing better on non-linear data than simple linear regression.\n",
    "Therefore, in this case, decision tree classifier is the better model for prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output prediction of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read test data from HW2_hr-analytics_test.csv\n",
    "test_data = pd.read_csv('./HW3 附件/HW2_hr-analytics_test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing onehot encoding on col: ['sales', 'salary']\n",
      "After operating ['sales']. (5000, 9) -> (5000, 18)\n",
      "After operating ['salary']. (5000, 18) -> (5000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "test_df = test_data.copy()\n",
    "col_not_num = []\n",
    "for col in test_df.columns: # Checking columns that are not numeric\n",
    "    if check_non_numeric_values(test_df, col): \n",
    "        col_not_num.append(col)\n",
    "\n",
    "print(f\"Doing onehot encoding on col: {col_not_num}\")\n",
    "for col in col_not_num: # onehot encode the col that is not numeric\n",
    "    test_df = onehot_encoding(test_df, col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up random state\n",
    "random_state = 42\n",
    "\n",
    "trans = True\n",
    "if trans: # 956 -> 957\n",
    "    scaler = StandardScaler()\n",
    "    test_df['average_montly_hours'] = scaler.fit_transform(test_df[['average_montly_hours']])\n",
    "\n",
    "X = test_df.copy()\n",
    "\n",
    "# Predict the data using decision tree classifier.\n",
    "y_real_pred = decision_tree_classifier.predict(X)\n",
    "y_real_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      left\n",
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        0\n",
      "...    ...\n",
      "4995     0\n",
      "4996     0\n",
      "4997     0\n",
      "4998     0\n",
      "4999     1\n",
      "\n",
      "[5000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the pred from (5000,) to (5000, 1).\n",
    "result = y_real_pred.reshape(-1, 1)\n",
    "\n",
    "# Create a DataFrame with one column 'left'.\n",
    "result_df = pd.DataFrame(data=result, columns=['left'])\n",
    "print(result_df)\n",
    "\n",
    "# Produce our end result.\n",
    "result_df.to_csv('HW2_hr-analytics_test_sol.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
