{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw4/hw4_2.ipynb 儲存格 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/liushiwen/Desktop/%E5%A4%A7%E5%9B%9B%E4%B8%8A/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%B0%8E%E8%AB%96/MachineLearning/hw4/hw4_2.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liushiwen/Desktop/%E5%A4%A7%E5%9B%9B%E4%B8%8A/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%B0%8E%E8%AB%96/MachineLearning/hw4/hw4_2.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liushiwen/Desktop/%E5%A4%A7%E5%9B%9B%E4%B8%8A/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E5%B0%8E%E8%AB%96/MachineLearning/hw4/hw4_2.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/torch/__init__.py:459\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[1;32m    446\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    447\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    456\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    457\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n\u001b[1;32m    460\u001b[0m     \u001b[39mif\u001b[39;00m name[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m name\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39mBase\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    461\u001b[0m         __all__\u001b[39m.\u001b[39mappend(name)\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 調整解析度\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "image_data = torchvision.datasets.ImageFolder('/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw4/reference', transform=data_transform)\n",
    "train_loader = DataLoader(image_data, batch_size=4, shuffle=True)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 100\n",
      "    Root location: /Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw4/reference\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(image_data.class_to_idx)\n",
    "print(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1529, 0.1569, 0.1608,  ..., 0.8078, 0.8000, 0.7843],\n",
      "         [0.1569, 0.1569, 0.1608,  ..., 0.7922, 0.7843, 0.7765],\n",
      "         [0.1529, 0.1529, 0.1490,  ..., 0.7725, 0.7804, 0.7882],\n",
      "         ...,\n",
      "         [0.1137, 0.1059, 0.0902,  ..., 0.1686, 0.1569, 0.1922],\n",
      "         [0.1216, 0.1098, 0.0902,  ..., 0.1529, 0.1647, 0.2039],\n",
      "         [0.1216, 0.1059, 0.0863,  ..., 0.2078, 0.1843, 0.1725]],\n",
      "\n",
      "        [[0.1725, 0.1725, 0.1765,  ..., 0.8000, 0.7882, 0.7765],\n",
      "         [0.1765, 0.1725, 0.1765,  ..., 0.7765, 0.7725, 0.7647],\n",
      "         [0.1725, 0.1686, 0.1647,  ..., 0.7569, 0.7647, 0.7725],\n",
      "         ...,\n",
      "         [0.1059, 0.0980, 0.0824,  ..., 0.1137, 0.1059, 0.1490],\n",
      "         [0.1137, 0.1020, 0.0824,  ..., 0.1020, 0.1137, 0.1608],\n",
      "         [0.1137, 0.0980, 0.0784,  ..., 0.1569, 0.1333, 0.1294]],\n",
      "\n",
      "        [[0.1569, 0.1647, 0.1765,  ..., 0.6902, 0.6549, 0.6314],\n",
      "         [0.1608, 0.1647, 0.1765,  ..., 0.6706, 0.6471, 0.6235],\n",
      "         [0.1569, 0.1608, 0.1686,  ..., 0.6510, 0.6431, 0.6431],\n",
      "         ...,\n",
      "         [0.1098, 0.1020, 0.0863,  ..., 0.0902, 0.0824, 0.1255],\n",
      "         [0.1176, 0.1059, 0.0863,  ..., 0.0745, 0.0863, 0.1333],\n",
      "         [0.1176, 0.1020, 0.0824,  ..., 0.1255, 0.1020, 0.0980]]])\n"
     ]
    }
   ],
   "source": [
    "print(image_data[0][0])\n",
    "# display(image_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "# Define the data transformations\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "image_data = torchvision.datasets.ImageFolder('/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw4/reference', transform=data_transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "dataset_size = len(image_data)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(image_data, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 64)  # Adjust the input size based on your image size\n",
    "        self.fc2 = nn.Linear(64, 2)  # Output size: 2 (for dog and cat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 56 * 56)  # Adjust the input size based on your image size\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6966755837202072\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 2/20, Loss: 0.6959164589643478\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 3/20, Loss: 0.696355578303337\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 4/20, Loss: 0.6964239805936814\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 5/20, Loss: 0.6994983226060867\n",
      "Validation Accuracy: 55.0%\n",
      "Epoch 6/20, Loss: 0.7002792119979858\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 7/20, Loss: 0.6930624932050705\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 8/20, Loss: 0.6979827374219895\n",
      "Validation Accuracy: 55.0%\n",
      "Epoch 9/20, Loss: 0.6940547287464142\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 10/20, Loss: 0.6943883031606675\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 11/20, Loss: 0.6954115778207779\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 12/20, Loss: 0.6939002215862274\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 13/20, Loss: 0.6947601526975632\n",
      "Validation Accuracy: 55.0%\n",
      "Epoch 14/20, Loss: 0.6973469853401184\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 15/20, Loss: 0.693847045302391\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 16/20, Loss: 0.6973284095525741\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 17/20, Loss: 0.6958928853273392\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 18/20, Loss: 0.69708351790905\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 19/20, Loss: 0.6955830335617066\n",
      "Validation Accuracy: 45.0%\n",
      "Epoch 20/20, Loss: 0.6941148549318313\n",
      "Validation Accuracy: 45.0%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model, loss function, and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Confusion Matrix (Training Set):\n",
      "[[ 0 39]\n",
      " [ 0 41]]\n",
      "AUROC (Training Set): 0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_predictions.extend(predicted.numpy())\n",
    "print(all_labels)\n",
    "print(all_predictions)\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "print(\"Confusion Matrix (Training Set):\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# AUROC\n",
    "# Assuming that outputs[:, 1] corresponds to the probability of the positive class (e.g., cat)\n",
    "auroc = roc_auc_score(all_labels, all_predictions)\n",
    "print(f\"AUROC (Training Set): {auroc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw4/HW4.pth\"\n",
    "torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1: Predicted class 1\n",
      "Image 2: Predicted class 1\n",
      "Image 3: Predicted class 1\n",
      "Image 4: Predicted class 1\n",
      "Image 5: Predicted class 1\n",
      "Image 6: Predicted class 1\n",
      "Image 7: Predicted class 1\n",
      "Image 8: Predicted class 1\n",
      "Image 9: Predicted class 1\n",
      "Image 10: Predicted class 1\n",
      "Image 11: Predicted class 1\n",
      "Image 12: Predicted class 1\n",
      "Image 13: Predicted class 1\n",
      "Image 14: Predicted class 1\n",
      "Image 15: Predicted class 1\n",
      "Image 16: Predicted class 1\n",
      "Image 17: Predicted class 1\n",
      "Image 18: Predicted class 1\n",
      "Image 19: Predicted class 1\n",
      "Image 20: Predicted class 1\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, image_folder):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_path in image_folder:\n",
    "            img = Image.open(image_path)\n",
    "            img = transforms.Resize((224, 224))(img)  # \n",
    "            img_tensor = transforms.ToTensor()(img)\n",
    "            output = model(img_tensor)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            predictions.append(predicted.item())\n",
    "\n",
    "    return predictions\n",
    "test_path = \"/Users/liushiwen/Desktop/大四上/機器學習導論/MachineLearning/hw4/test\"\n",
    "test_folder =[]\n",
    "for ii in range(20):\n",
    "    test_folder.append(f\"{test_path}/pic{ii+1}.jpg\")\n",
    "# test_folder = [f'{test_path}/pic1.jpg', f'{test_path}/pic2.jpg', f'{test_path}/pic3.jpg']  # Replace with actual image paths\n",
    "testing_model = SimpleCNN()\n",
    "testing_model.load_state_dict(torch.load(file_path))\n",
    "predictions = test_model(testing_model, test_folder)\n",
    "\n",
    "# Display the predictions\n",
    "for i, prediction in enumerate(predictions, start=1):\n",
    "    print(f\"Image {i}: Predicted class {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
