{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import datetime\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('./HW2 附件/HW2_bike-sharing_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8386, 13) -> (8386, 16)\n",
      "      holiday  workingday  weather   temp   atemp  humidity  windspeed  count  \\\n",
      "0           0           0        1   9.84  14.395        81     0.0000     16   \n",
      "1           0           0        1   9.02  13.635        80     0.0000     40   \n",
      "2           0           0        1   9.02  13.635        80     0.0000     32   \n",
      "3           0           0        1   9.84  14.395        75     0.0000     13   \n",
      "4           0           0        1   9.84  14.395        75     0.0000      1   \n",
      "...       ...         ...      ...    ...     ...       ...        ...    ...   \n",
      "8381        0           1        1  16.40  20.455        50    26.0027    562   \n",
      "8382        0           1        1  15.58  19.695        50    23.9994    569   \n",
      "8383        0           1        1  15.58  19.695        50    26.0027    336   \n",
      "8384        0           1        1  14.76  17.425        57    15.0013    241   \n",
      "8385        0           1        1  13.94  17.425        61     6.0032    129   \n",
      "\n",
      "      year  month  day  hour  season_1  season_2  season_3  season_4  \n",
      "0     2011      1    1     0         1         0         0         0  \n",
      "1     2011      1    1     1         1         0         0         0  \n",
      "2     2011      1    1     2         1         0         0         0  \n",
      "3     2011      1    1     3         1         0         0         0  \n",
      "4     2011      1    1     4         1         0         0         0  \n",
      "...    ...    ...  ...   ...       ...       ...       ...       ...  \n",
      "8381  2012     12   19    17         0         0         0         1  \n",
      "8382  2012     12   19    18         0         0         0         1  \n",
      "8383  2012     12   19    19         0         0         0         1  \n",
      "8384  2012     12   19    20         0         0         0         1  \n",
      "8385  2012     12   19    22         0         0         0         1  \n",
      "\n",
      "[8386 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def seperate_dt(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    # # Extract year, month, day, hour, minute, and second as separate columns\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    return df\n",
    "\n",
    "# check nan\n",
    "def check_nan(df):\n",
    "    return df.isna().any().any()\n",
    "\n",
    "# turn season into encoding\n",
    "def onehot_encoding(df, column_name):\n",
    "    df_encoded = pd.get_dummies(df, columns=[column_name], prefix=[column_name])\n",
    "    print(df.shape, \"->\", df_encoded.shape)\n",
    "    return df_encoded\n",
    "\n",
    "def standardization(df):\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the data using StandardScaler\n",
    "    df_standardized = scaler.fit_transform(df)\n",
    "    df_standardized = pd.DataFrame(df_standardized, columns=df.columns)\n",
    "    return df_standardized\n",
    "\n",
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    global filename\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "\n",
    "def normalization(df):\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    # Fit and transform the data using MinMaxScaler\n",
    "    df_normalized = scaler.fit_transform(df)\n",
    "    df_normalized = pd.DataFrame(df_normalized, columns=df.columns)\n",
    "    return df_normalized\n",
    "# filename = \"Linear_Regression.txt\"\n",
    "# pprint(\"This is a Test\", True)\n",
    "df = data.copy()\n",
    "df = seperate_dt(df).drop(columns=['datetime'])\n",
    "check_nan(df)\n",
    "df = onehot_encoding(df,'season')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate into X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8386, 15), (8386,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['count'])\n",
    "y = df['count']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up dataset into Train, Val and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6708, 15) (6708,)\n",
      "(839, 15) (839,)\n",
      "(839, 15) (839,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liushiwen/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.707e+04, tolerance: 2.224e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/liushiwen/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.707e+04, tolerance: 2.224e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics:\n",
      "MSE:  11073.946481812762\n",
      "R-squared:  0.66603473723869\n",
      "Voting Regressor Metrics:\n",
      "Mean Squared Error: 10024.902264600714\n",
      "R-squared: 0.6553502398509436\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "linear_regression = LinearRegression()\n",
    "poly3 = PolynomialFeatures(degree=3)\n",
    "poly4 = PolynomialFeatures(degree=4)\n",
    "lasso_regression4 = make_pipeline(poly4,StandardScaler(), Lasso())\n",
    "poly_regression3 = make_pipeline(poly3, linear_regression)\n",
    "\n",
    "# Create a voting ensemble with the individual regressors\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('lasso0', lasso_regression4),\n",
    "    ('lasso1', lasso_regression4),\n",
    "    ('poly0', poly_regression3),\n",
    "    ('poly1', poly_regression3),\n",
    "    ('poly2', poly_regression3),\n",
    "])\n",
    "\n",
    "# Fit the ensemble model to the training data\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the ensemble model\n",
    "y_train_pred = voting_regressor.predict(X_train)\n",
    "y_train_pred = abs(y_train_pred).astype(int)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(\"Training Set Metrics:\")\n",
    "print(\"MSE: \", mse_train)\n",
    "print(\"R-squared: \", r2_train)\n",
    "\n",
    "# Make predictions with the ensemble model\n",
    "y_pred = voting_regressor.predict(X_val)\n",
    "# Calculate the Mean Squared Error and R-squared\n",
    "y_pred = abs(y_pred).astype(int)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(\"Voting Regressor Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245.52041700503884\n"
     ]
    }
   ],
   "source": [
    "ape = sum(np.abs((y_val - y_pred) / y_val) * 100)\n",
    "print(ape/ len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Metrics:\n",
      "MSE:  19760.88908765653\n",
      "R-squared:  0.4040561305407345\n",
      "Voting Regressor Metrics:\n",
      "Mean Squared Error: 16446.34684147795\n",
      "R-squared: 0.43458506181562984\n"
     ]
    }
   ],
   "source": [
    "# Base model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_pred = abs(y_train_pred).astype(int)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "print(\"Training Set Metrics:\")\n",
    "print(\"MSE: \", mse_train)\n",
    "print(\"R-squared: \", r2_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = abs(y_pred).astype(int)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"Voting Regressor Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor Metrics:\n",
      "Mean Squared Error: 12295.0\n",
      "R-squared: 0.6166418276818644\n",
      "Voting Regressor Metrics:\n",
      "Mean Squared Error: 19309.891537544696\n",
      "R-squared: 0.3979174682802302\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_regressor.predict(X_test)\n",
    "y_pred = abs(y_pred).astype(int)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Voting Regressor Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = abs(y_pred).astype(int)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Voting Regressor Metrics:\")\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./HW2 附件/HW2_bike-sharing_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 12) -> (2500, 15)\n",
      "      holiday  workingday  weather   temp   atemp  humidity  windspeed  year  \\\n",
      "0           0           0        3  14.76  17.425        93     8.9981  2012   \n",
      "1           0           0        1  10.66  12.880        41    15.0013  2011   \n",
      "2           0           1        2  13.94  18.180        42     0.0000  2012   \n",
      "3           1           0        1  33.62  37.120        43     6.0032  2011   \n",
      "4           0           1        1  38.54  41.665        29    16.9979  2012   \n",
      "...       ...         ...      ...    ...     ...       ...        ...   ...   \n",
      "2495        0           1        3  18.04  21.970        77    15.0013  2011   \n",
      "2496        0           1        1   9.02  11.365        60     8.9981  2011   \n",
      "2497        0           0        3  17.22  21.210        67    16.9979  2011   \n",
      "2498        0           0        3  17.22  21.210        88    16.9979  2011   \n",
      "2499        0           0        1  26.24  30.305        65    11.0014  2012   \n",
      "\n",
      "      month  day  hour  season_1  season_2  season_3  season_4  \n",
      "0        12    9    17         0         0         0         1  \n",
      "1         2   12    20         1         0         0         0  \n",
      "2        12   12    13         0         0         0         1  \n",
      "3         7    4    15         0         0         1         0  \n",
      "4         7   17    14         0         0         1         0  \n",
      "...     ...  ...   ...       ...       ...       ...       ...  \n",
      "2495      4   12    18         0         1         0         0  \n",
      "2496      3    4     9         1         0         0         0  \n",
      "2497     10    1     7         0         0         0         1  \n",
      "2498      1    1    19         1         0         0         0  \n",
      "2499      8   12     6         0         0         1         0  \n",
      "\n",
      "[2500 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df = test_data.copy()\n",
    "test_df = seperate_dt(test_df).drop(columns=['datetime'])\n",
    "check_nan(test_df)\n",
    "test_df = onehot_encoding(test_df,'season')\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 15)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = test_df\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real_pred = voting_regressor.predict(X)\n",
    "y_real_pred = abs(y_real_pred).astype(int)\n",
    "y_real_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      count\n",
      "0       194\n",
      "1        86\n",
      "2       285\n",
      "3       423\n",
      "4       276\n",
      "...     ...\n",
      "2495    158\n",
      "2496    102\n",
      "2497    106\n",
      "2498     55\n",
      "2499    186\n",
      "\n",
      "[2500 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "result = y_real_pred.reshape(-1, 1)  # Reshape to (1000, 1)\n",
    "# Create a DataFrame with one column 'left'\n",
    "result_df = pd.DataFrame(data=result, columns=['count'])\n",
    "print(result_df)\n",
    "result_df.to_csv('HW2_bike-sharing_test_sol.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
