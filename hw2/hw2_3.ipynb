{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "data = pd.read_csv('./HW2 附件/HW2_hr-analytics_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing onehot encoding on col: ['sales', 'salary']\n",
      "(10000, 10) -> (10000, 19)\n",
      "(10000, 19) -> (10000, 21)\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "# check nan\n",
    "def check_nan(df):\n",
    "    return df.isna().any().any()\n",
    "\n",
    "def onehot_encoding(df, column_name):\n",
    "    df_encoded = pd.get_dummies(df, columns=[column_name], prefix=[column_name])\n",
    "    print(df.shape, \"->\", df_encoded.shape)\n",
    "    return df_encoded\n",
    "\n",
    "def pprint(output = '\\n', show_time = False): # print and fprint at the same time\n",
    "    global filename\n",
    "    print(output)\n",
    "    with open(filename, 'a') as f:\n",
    "        if show_time:\n",
    "            f.write(datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S] \"))\n",
    "\n",
    "        f.write(str(output))\n",
    "        f.write('\\n')\n",
    "        \n",
    "def check_non_numeric_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Check if any value in the specified column is not int or float.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to check.\n",
    "    column_name (str): The name of the column to check.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if any non-numeric value is found, False otherwise.\n",
    "    \"\"\"\n",
    "    # Get the specified column\n",
    "    column = df[column_name]\n",
    "\n",
    "    # Check if any value is not int or float\n",
    "    non_numeric_values = column[~column.apply(lambda x: isinstance(x, (int, float)))]\n",
    "    \n",
    "    return not non_numeric_values.empty\n",
    "\n",
    "def count_unique_values(df, column_name):\n",
    "    \"\"\"\n",
    "    Count the number of unique values in the specified column.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame to check.\n",
    "    column_name (str): The name of the column to count unique values for.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of unique values.\n",
    "    \"\"\"\n",
    "    unique_values = df[column_name].nunique()\n",
    "    return unique_values\n",
    "\n",
    "col_not_num = []\n",
    "for col in df.columns:\n",
    "    if check_non_numeric_values(df, col):\n",
    "        col_not_num.append(col)\n",
    "\n",
    "print(f\"Doing onehot encoding on col: {col_not_num}\")\n",
    "for col in col_not_num:\n",
    "    df = onehot_encoding(df, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'left'\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Accuracy: 0.763\n",
      "Improved Accuracy: 0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liushiwen/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liushiwen/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/liushiwen/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Method 4: Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Use SelectKBest to select the top k features based on ANOVA F-statistics\n",
    "k = 1  # Set the number of features to select\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_val_selected = selector.transform(X_val)\n",
    "\n",
    "# Create a new logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Fit the model with selected features\n",
    "logistic_regression.fit(X_train_selected, y_train)\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "y_pred = logistic_regression.predict(X_val_selected)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Improved Accuracy:\", accuracy)\n",
    "\n",
    "# Method 5: Class Imbalance Handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Use SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a logistic regression model on the resampled data\n",
    "logistic_regression.fit(X_resampled, y_resampled)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = logistic_regression.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Improved Accuracy:\", accuracy)\n",
    "\n",
    "# Method 6:\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create polynomial features\n",
    "degree = 5  # Choose the degree of polynomial features\n",
    "polyreg = make_pipeline(PolynomialFeatures(degree), LogisticRegression())\n",
    "polyreg.fit(X_train, y_train)\n",
    "y_pred = polyreg.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Improved Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liushiwen/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Accuracy: 0.782\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'solver': ['liblinear'],  # Suitable for small datasets\n",
    "}\n",
    "\n",
    "# Create a logistic regression model\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# Perform hyperparameter tuning with cross-validation\n",
    "grid_search = GridSearchCV(logistic_regression, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Improved Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "[[700  59]\n",
      " [165  76]]\n",
      "Accuracy: 0.68\n",
      "Precision: 0.2074074074074074\n",
      "Recall (Sensitivity): 0.11618257261410789\n",
      "F1 Score: 0.14893617021276595\n",
      "ROC AUC: 0.48760380277609217\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "print(y_pred.shape)\n",
    "# Calculate the confusion matrix\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "print(confusion)\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    # Calculate recall (sensitivity)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(\"Recall (Sensitivity):\", recall)\n",
    "\n",
    "    # Calculate F1 score (harmonic mean of precision and recall)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    # Calculate ROC AUC (Receiver Operating Characteristic Area Under the Curve)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "metrics(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     left\n",
      "0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "..    ...\n",
      "995     0\n",
      "996     0\n",
      "997     0\n",
      "998     0\n",
      "999     0\n",
      "\n",
      "[1000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "result = y_pred.reshape(-1, 1)  # Reshape to (1000, 1)\n",
    "# Create a DataFrame with one column 'left'\n",
    "result_df = pd.DataFrame(data=result, columns=['left'])\n",
    "print(result_df)\n",
    "result_df.to_csv('HW2_hr-analytics_test_sol.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
